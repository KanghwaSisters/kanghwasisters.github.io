# 파이썬과 케라스로 배우는 강화학습

## 1주차 (03.17)

### 1. 인공신경망 개념

—

- ** 노드와 화살표 **
	1. 인공신경망의 계층구조: 입력층, 은닉층, 출력층, 항상 이 순서로 정보가 흐른다.
		- 심층신경망: 은닉층이 2개 이상인 인공신경망
		- Layer: 모든 인공신경망 모델의 기본 단위
			- Fully-connected layer: 가장 간단한 층 (Dense라는 모듈의 클래스 선언으로 이용)
	2. 화살표: *시냅스*의 역할, 연결의 비중을 조절한다.
		- 만약 연결을 다중으로 받으면 각각을 다른 비중으로 생각한다.
	3. 노드: *뉴런*의 역할
	4. 기본 구조: 입력 -(가중치)-> 편향 -> 활성함수 -> 출력
		- 활성함수
			- ReLU, Tanh, Sigmoid 등을 이용 (단순히 switch처럼 0, 1로 활성화하지 않는다.)
				- Sigmoid: 0~1 연속값을 return, 0 or 1로 활성상태를 나타내는 게 아니다.
				$$
				f(x) = frac{1}{1+e^{-x}}
				$$
				- ReLU (Rectified Linear Unit): 입력이 0보다 크면 그대로, 아니면 0으로 return
				- 선형 V.S. 비선형함수: 문제가 복잡해 선형으로 구분이 불가능한 경우가 많다.
				(대부분의 신경망이 렐루를 사용하고 있다.)
			- 활성함수의 입력 = sum of {(입력)*(가중치)+(편향)}

- ** 딥러닝 **
	1. 딥러닝이란?
	- 딥러닝 이전의 기계학습에서는 전문가가 직접 특징을 추출하고 이를 썼으나, 이는 개발, 평가, 보완적 측면에서 부정적이다.
	- 딥러닝은 딥러닝 알고리즘이 입력 특징을 추출한다. (Better)
	2. 학습
	- 가중치와 편향을 학습하는 것
	- 지도학습:
		- 학습 데이터: 입력 + 정답(타깃)
		- 출력: 예측값
		- 오차함수: 타깃과 예측의 오차 계산
			- ex. 평균제곱오차(MSE): $ ** 오차 ** = (타깃 - 예측)^2 $ -> 가중치/편향을 업데이트해서 오차 조정 -> 옵티마이저가 모델 업데이트
		- 역전파 (Back-propagation) / 경사하강법: 오차 함수를 통해 가중치/편향의 오차에 대한 기여도를 계산한다.
		$$
		** 업데이트 값 ** \propto {오차} * {오차 기여도}
		$$
		- 오차 기여도 = 해당 오차에 대한 편미분값 => 증감 여부/크기 결정
			- 미분값이기에 경사라고 부르기도 한다.
		- 모든 경사하강법(SGD, RMSprop, Adam 등)은 학습 속도(rate)라는 변수를 갖는다.
			- 학습 속도: 신경망 업데이트시 업데이트 크기 결정

- ** 인공신경망 라이브러리 (케라스) **
 - 인공신경망 프레임워크: 이미 인공신경망을 구현 -> 여기서 발전시켜 사용

___

### 인공신경망 예제

import tensorflow as tf
from tensorflow.keras.layers import Dense
from tensorflow.keras.optimizers import Adam

# load data
mnist = tf.keras.datasets.fashion_mnist
(x_train, y_train), (x_test, y_test) = mnist.load_data()

# normalize pixels from 0~255 to 0~1
x_train, x_test = x_train / 255.0, x_test / 255.0

# Definition of Model
‘’’
- 입력층 노드 개수: ** 784 **, 은닉층: ** 256 **, ** 128 **, 출력층: ** 10 **
- 입력 * (28,28) * 2차원 배열이 1차원 배열 * (784,) *로 늘려 ReLU 함수를 거치다가 출력층에서는 Softmax 함수를 거친다.
	- -1 파라미터로 해당 차원을 자동으로 계산
	- return = 합이 1인 확률 10개 -> 각 레이블에 대한 예측 확률을 의미
- tf.keras.Model을 상속받는 클래스 선언 후 초기화 함수로 변형
‘’’
class Model(tf.keras.Model):
	def __init__(self):
		super(MOdel, self).__init__()
		self.input_layer = Dense(256, activation=‘relu’, input_shape(784,))
		self.hidden_layer = Dense(128, activation=‘relu’)
		self.output_layer = Dense(10, activation=‘softmax’)

	def call(self, x):
		x = self.input_layer(x)
		x = self.hidden_layer(x)
		x = self.output_layer(x)
		return x

# Model, Loss, Optimizer
‘’’
- 데이터셋은 이제 작은 단위인 ** 미니 배치 **로 쪼개져서 학습에 쓰일 것이다.
	- 배치: 데이터 셋을 쪼갠 것 * cf. 미니 배치: 배치를 쪼갠 것 *
	- why? 모든 데이터에 대해 오차함수를 돌리는 것은 자원 낭비
- 오차함수 Cross Entropy: (나중에)
- 옵티마이저 Adam
- epoch: 전체 데이터 학습 수행 횟수
‘’’
model = CNN()
cross_entropy = tf.keras.losses.CategoricalCrossentropy(from_logits=False)
optimizer = Adam(1e-4)

# Mini batch
batch_size = 32
num_train_data = x_train-shape[0]
num_test_data = x_test.shape[0]

num_epoch = 10
for e in range(num_epoch):
	for i in range(num_train_data//batch_size): # 배치 하나 만큼씩 돌아
		# 미니 배치 개수 만큼 데이터 fetch
		x_batch = x_train[i * batch_size : (i+1) * batch_size]
		y_batch = y_train[i * batch_size : (i+1) * batch_size]
		# 전처리: 2차원 배열 -> 1차원, 스칼라 값은 One-hot encoding으로 벡터화
		x_batch = x_batch.reshape(-1, 28 * 28)
		y_batch = tf.one_hot(y_batch, 10)

‘’’
tf.GradientTape (): 역전파 알고리즘의 효과적인 수행을 위해 모델 입력~출력 계산 과정을 저장하는 함수
	-> with 문 안에서 일어난 계산을 모두 tape에 저장한다.
	-> 저장된 값으로 tape.gradient() 구한다. (= 편미분 값을 구한다.)
‘’’
		# 계산 과정 기록용 tape scope 선언
		model_params = model.trainable_variables
		with tf.GradientTape() as tape:
			# 모델로 예측
			predicts = model(x_batch)
			# 오류함수 계산
			losses = cross_entropy(predicts, y_batch)
		# tape를 통해 gradient 계산
		grads = tape.gradient(losses, model_params)
		# 계산한 그레이디언트를 통해 모델 업데이트
		optimizer.apply_gradients(zip(grads, model_params))

___

### 과제

- 활성화 함수 선택시: ReLU, Tanh, Sigmoid의 함수 선택 기준이 무엇인가요?
- SGD, RMSprop, Adam 등의 경사하강법 중 옵티마이저를 선택하는 기준이 있나요?
- 배치랑 개념적으로 크게 달라보이지 않는데 미니 배치로 쪼개는 이유는 무엇인가요?
